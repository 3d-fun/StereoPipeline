\chapter{Correlation}
\label{ch:correlation}

In this chapter we will dive much deeper into understanding the core
algorithms in the Stereo Pipeline.  We start with an overview of the
five stages of stereo reconstruction.  Then we move into an in-depth
discussion and exposition of the correlation algorithms in the {\em
  disparity map initialization} and {\em subpixel refinement}

The goal of this chapter is to build an intuition for the stereo
correlation process.  This will help users to identify unusual results
in their DEMs and hopefully eliminate them by tuning various
parameters in the {\tt stereo.default} file.  For scentists and
engineers who are using DEMs produced with the Stereo Pipeline, this
chapter may help to answer the question, ``What is the Stereo Pipeline
doing to the raw data to produce this DEM?''  

A related question that is commonly asked is, ``How accuarate is a DEM
produced by the Stereo Pipeline?''  This chapter does not yet address
matters of accuracy \& error, however we have several efforts underway
to quantify the accuracy of Stereo Pipeline-derived DEMs, and will be
publishing more information about that shortly.  Stay tuned.

\section{Overview of the Stereo Reconstruction Process}

The entire stereo correlation process, from raw input images to a
point cloud or DEM, can be viewed as a multistage pipeline as depicted
in Figure~\ref{fig:asp}.

\begin{figure}[tb]
  \centering
  \includegraphics[width=13cm]{images/asp}
  \caption{Flow of data through the Stereo Pipeline.}
  \label{fig:asp}
\end{figure}

\subsection{Pre-processing}

The first optional (but recommended) step in the process is least
squares Bundle Adjustment, which is described in detail in
Chapter~\ref{ch:bundle_adjustment}. 

Next, the left and right images are roughly aligned using one of two
methods: (1) a linear transform of the right image based on automated
tie-point measurements, or (2) map projection of both the left and
right image using the ISIS {\tt cam2map} command.  The former option
is done automatically by the stereo pipeline when the
DO\_INTERESTPOINT\_ALIGNMENT variable in the {\tt stereo.default} file
is turned on.  

The latter option, running {\tt cam2map}, must be carried out by the
user prior to invoking the {\tt stereo} command.  Map projecting the
images using ISIS eliminates any usual distorition in the image due to
the unusual camera acquisition modes (e.g. pitching ``ROTO'' maneuvers
during image acquisition for MOC, or highly eliptical orbits and
changing line exposure times for HRSC).  It also eliminates some of
the perspective differences in the image pair that are due to large
terrain features by taking the existing low-res terrain model
(e.g. MOLA or ULCN 2005) into account.  

In essence, map projecting the images results in a pair of very
closely matched images that are as close to ideal as possible given
existing information.  This leaves only small perspective differences
in the images, which are exactly the features that the stereo
correlation process is designed to detect.  

For this reason, we highly recommend map projection for pre-alignment
of most stereo pairs.  In either case, the pre-alignment step is
essential for performance because it ensures that the disparity search
space is bounded to a known area.  In both cases, the effects of
pre-alignment are taken into account later in the process during
Triangulation, so you do not need to worry that pre-alignment will
compromise the geometric integrity of your DEM.

In some cases the pre-processing step may also normalize the pixel
values in the left and right images to bring them into the same
dynamic range.  Various options in the {\tt stereo.default} file
effect whether/how normalization is carried out, including
DO\_INDIVIDUAL\_NORMALIZATION and FORCE\_USE\_ENTIRE\_RANGE.  Although
the defaults work in most cases, the use of these normalization steps
can vary from data set to data set, so we recommend you refer to the
examples in Chapter \ref{ch:examples} to see these are necessary in
your use case.

Finally, pre-processing can perform some filtering of the input images
(as determined by PREPROCESSING\_FILTER\_MODE) to reduce noise and
extract edges in the images.  When active, these filters apply a
gaussian blur with a sigma of SLOG\_KERNEL\_WIDTH that can improve
results for noisy images\footnote{PREPROCESSING\_FILTER\_MODE must be
  chosen carefully in conjunction with COST\_MODE.  (See
  Appendix~\ref{ch:stereodefault})}.  The pre-processing modes that
extract image edges are useful for stereo pairs that do not have the
same lighting conditions, contrast, and absolute
brightess~\cite{Nishihara84practical}.  We recommend that you use the
defaults for these parameters to start with, and then experiment only
if your results are suboptimal.

\subsection{Disparity Map Initialization}

Correlation is the process at the heart of the Stereo Pipeline.  It is
a collection of algorithms that compute correspondences between pixels
in the left image and pixels in the right image.  The map of these
correspondences is called a {\em disparity map}.  You can think of a
disparity map as an image whose pixel {\em locations} correspond to
the pixel $(u,v)$ in the left image, and whose pixel {\em values}
contain the horizontal and vertical offsets $(d_u, d_v)$ to the
matching pixel in the right image, which is $(u+d_u, v+d_v)$.  

The correlation process attempts to find a match for every pixel in
the left image.  For large images (e.g. from HiRISE or LROC), this is
very, very expensive computationally, so the correlation process is
split into two stages.  The {\em disparity map initialization} step
computes approximate correspondences using a pyramid-based search that
is highly optimized for speed, but trades this speed for accuracy.
The results of disparity map initialization are integer-valued
disparity estimates.  The {\em sub-pixel refinement} step takes these
integer estimates as initial conditions for an iterative optimization
and refines them using the algorithm discussed in the next section.

We employ several optimizations to accelerate disparity map
initialization: (1) a box filter-like accumulator that reduces
duplicate operations during correlation~\cite{Sun02rectangular}; (2) a
coarse-to-fine pyramid based approach where disparities are estimated
using low resolution images, and then successively refined at higher
resolutions; and (3) partitioning of the disparity search space into
rectangular sub-regions with similar values of disparity determined in
the previous lower resolution level of the
pyramid~\cite{Sun02rectangular}.

\begin{figure}[bt]
  \centering
  \includegraphics[width=13cm]{images/correlation/correlation}
  \caption{The correlation algorithm in disparity map initialization
    uses a sliding template window from the left image to find the
    best match in the right image.  The size of the template window
    can be adjusted using the H\_KERN and V\_KERN parameters in the
    {\tt stereo.default} file, and the search range can be adjusted
    using the \{H,V\}\_CORR\_\{MIN/MAX\} parameters.}
  \label{fig:correlation_window}
\end{figure}

Correlation itself is carried out by sliding a small, rectangular
template window from the from left image over the specified search
region of the right image, as in Figure~\ref{fig:correlation_window}.
The ``best'' match is determined by applying a cost function that
compares the two windows.  The COST\_MODE variable allows you to
choose one of three cost functions, though we recommend normalized
cross correlation~\cite{Menard97:robust}, since it is most robust to
slight lighting and contrast variation in between a pair of images.

\subsubsection{Debugging Disparity Map Initialization}

Not all pixels will be succesfully matched during stereo matching.
Matching may fail due to a variety of reasons:

\begin{itemize}
\item In regions where the images do not overlap, there should be no
  valid matches in the disparity map.
\item Match quality may be poor in regions of the images that have
  different lighting conditions, contrast, or absolute brightness.  
\item Areas that have image content with very little texture or
  extremely low contrast may have an insufficient signal to noise
  ratio, and will be rejected by the correlator.
\item Areas that are highly distorted due to different image
  perspective, such as crater and canyon walls, may exhibit poor
  matching performance.
\end{itemize}

Bad matches, often called ``blunders'' or ``artifacts'' are also
common, and can happen for many of the same reasons listed above.  The
Stereo Pipeline does its best to automatically detect and eliminate
these blunders, but the effectiveness of these outlier rejection
strategies does vary depending on the quality of the input imagery.

When tuning up your {\tt stereo.default} file, you will find that it
is very helpful to look at the raw output of the disparity map
initialization step.  This can be done using the {\tt disparitydebug}
tool, which converts the {\tt <ouput\_prefix>-D.exr} file into a pair
of normal images that contain the horizontal and vertical components
of disparity.  You can open these in a standard image viewing
application and see immediately which pixels were matched
successfully, and which were not.  Stereo matching blunders are
usually also obvious when inspecting these images.  With a good
intuition for the effects of various {\tt stereo.default} parameters
and a good intuition for reading the output of {\tt disparitydebug},
it is possible to quickly identify and address most problems.

\section{Sub-pixel Refinement}
\label{sec:subpixel}

Once disparity map initialization is complete, every pixel in the
disparity map will either have an estimated disparity value, or it
will be marked as invalid.  All valid pixels are then adjusted in the
sub-pixel refinement stage based on the SUBPIXEL\_MODE setting.

The first mode is parabola-fitting sub-pixel refinement (
SUBPXEL\_MODE 1 ).  This technique fits a 2D parabola to points on the
correlation cost surface in an 8-connected neighborhood around the
cost value that was the ``best'' as measured during disparity map
initialization. The parabola's minimum can then be computed
analytically and taken as as the new sub-pixel disparity value.

This method is easy to implement and extremely fast to compute, but it
exhibits a problem known as pixel-locking: the sub-pixel disparities
tend toward their integer estimates and can create noticable "stair
steps" on surfaces that should be
smooth~\cite{Stein06:attenuating},~\cite{Szeliski03sampling}.  See
e.g. Figure~\ref{fig:parabola_subpixel}. Furthermore, the parabola
subpixel mode is not capable of refining a disparity estimate by more
than 1.0 pixels, so although it produces smooth disparity maps, these
results are not much more accurate than the results that come out of
the disparity map initialization in the first place.  However, the
speed of this method makes it very useful as a ``draft'' mode for
quickly generating a DEM for visualization (i.e. non-scientific)
purposes.

\begin{figure}[tb]
\centering
  \subfigure[{\tt Left Image}]{\includegraphics[width=2in]{images/correlation/sub4-AS15-M-1134_crop.png}\label{fig:left_input_image}}
  \subfigure[{\tt Parabola Subpixel Mode}]{\includegraphics[width=2in]{images/correlation/3D_mode0.png}\label{fig:parabola_subpixel}}
  \subfigure[{\tt Bayes EM Subpixel Mode}]{\includegraphics[width=2in]{images/correlation/3D_mode3.png}}

  \subfigure[{\tt Right Image}]{\includegraphics[width=2in]{images/correlation/sub4-AS15-M-1135_crop.png}\label{fig:right_input_image}}
  \subfigure[{\tt Parabola Hillshade}]{\includegraphics[width=2in]{images/correlation/hillshade_mode0.png}}
  \subfigure[{\tt Bayes EM Hillshade}]{\includegraphics[width=2in]{images/correlation/hillshade_mode3.png}}

\caption{Left: Input images.  Center: results using the parabola draft
  subpixel mode (SUBPIXEL\_MODE = 1). Right: results using the Bayes
  EM high quality subpixel mode (SUBPIXEL\_MODE = 2).}
\label{fig:parabola_results}
\end{figure}

For high quality results, we recommend SUBPIXEL\_MODE 2: the Bayes EM
weighted affine adaptive window correlator.  This advanced method for
produces extremely high quality stereo matches that exhibit a high
degree of immunity to image noise.  For example Apollo Metric Camera
images are affected by two types of noise inherent to the scanning
process: (1) the presence of film grain and (2) dust \& lint
particles.  The former gives rise to noise in the DEM values that wash
out real features, and the latter causes incorrect matches or hard to
detect blemishes in the DEM.  Attenuating the effect of these scanning
artifacts while simultaneously refining the integer disparity map to
sub-pixel accuracy has become a critical goal of our system, and is
necessary for processing real-world data sets such as the Apollo
Metric Camera data.

The Bayes EM subpixel correlator also features a deformable template
window from the left image that can be rotated, scaled, and tranlated
as it zeros in on the on correct match in the right image.  This
adaptive window is essential for computing accurate matches on crater
or canyon walls, and on other areas with significant perspective
distortion due to foreshortening.  

This affine-adaptive behavior is based on the Lucas-Kanade template
tracking algorithm; a classic in the field of computer vision.  We
have extended this classic technique; develeloping a bayesian model
that treats the Lucas-Kanade parameters as random variables in an
Expectation Maximization (EM) framework.  This statistical model also
includes a gaussian mixture component to model image noise that is the
basis for the robustness of our algorithm.  We will not go into depth
on our approach here, but we encourage interested readers to read our
papers on the topic~\cite{nefian:bayes_em, broxton:isvc09}.

However we do note that, like the computations in the disparity map
initialization stage, we adopt a multi-scale approach for sub-pixel
refinement. At each level of the pyramid, the algorithm is initialized
with the disparity determined in the previous lower resolution level
of the pyramid, thereby allowing the subpixel algorithm to shift the
results of the disparity intialization stage by many pixel if a better
match can be found using the affine, noise-adapted window.  Hence,
this sub-pixel algorithm is able to significantly improve upon the
results to yield a high quality, high resolution result.

\subsection{Triangulation}



The Stereo Pipeline uses geometric camera models available in
ISIS~\cite{anderson08:isis}.  These highly accurate models are
customized for each instrument that ISIS supports.  Each ISIS ``cube''
file contains all of the information that is required by the Stereo
Pipeline to produce a camera model for that observation.

\begin{figure}[h]
\centering
  \subfigure[{\tt Framing Camera Model}]{\includegraphics[width=3in]{images/correlation/pinhole_model}\label{fig:framing}}
  \subfigure[{\tt Pushbroom Camera Model}]{\includegraphics[width=3in]{images/correlation/linescan_model}\label{fig:linescan}}
\caption{Most remote sensing cameras fall into two generic categories
  based on their basic geometry.  Framing cameras (left) capture an
  instantaneous two-dimensional image.  Linescan cameras (right)
  capture images one scan line at a time, building up an image over
  the course of several seconds as the satellite moves through the
  sky.}
\label{fig:camera_models}
\end{figure}

ISIS camera models account for all aspects of camera geometry,
including both intrinsic (i.e. focal length, pixel size, and lens
distortion) and extrinsic (e.g. camera position and orientation)
camera parameters.  Taken together, these parameters are sufficent to
``forward project'' a 3D point in the world onto the image plane of
the sensor.  It is also possible to ``back project'' from the camera's
center of projection through a pixel corresponding to the original 3D
point.

\begin{figure}[b!]
  \centering
  \includegraphics[width=10cm]{images/correlation/triangulation}
  \caption{Once a disparity map has been generated and refined, it can
    be used in combination with the geometric camera models to compute
    the locations of 3D points on the surface of Mars.  This figure
    shows the position and orientation of the Mars Global Surveyor at
    two points in time where it captured images in a stereo pair.}
  \label{fig:triangulation}
\end{figure}

Notice, however, that forward and back projection are not symmetric
operations.  One camera is sufficient to ``image'' a 3D point onto a
pixel located on the image plane, but the reverse is not true.  Given
only a single camera and a pixel location $x = (u,v)$ that is the
image of an unknown 3D point $P = (x,y,z)$, it is only possible to
determine that $P$ lies somewhere along a ray that emanates from the
camera's center of projection through the pixel location $x$ on the
image plane (see Figure~\ref{fig:camera_models}).

Alas, once images are captured, the route from image pixel back to 3D
points in the real world is through back projection, so we must bring
more information to bear on the problem of uniquely reconstructing our
3D point.  In order to determine $P$ using back projection, we need
{\em two} cameras that both contain pixel locations $x_1$ and $x_2$
where $P$ was imaged.  Now, we have two rays that converge on a point
in 3D space (see Figure~\ref{fig:triangulation}). The location where
they meet must be the original location of $P$.

In practice, the two rays rarely intersect perfectly because any
slight error in the camera position or pointing information will
effect the rays' positions as well.  Instead, we take the {\em closest
  point of intersection} of the two rays as the location of point $P$.

Additionally, the actual distance between the rays at this point is an
interesting and important error metric that measures how
self-consistent our two camera models are for this point.  You will
learn in the next chapter that this information, when computed and
averaged over all reconstructed 3D points, can be a valuable statistic for
determining whether to carry out bundle adjusment.





